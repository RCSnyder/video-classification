{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03bc84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook processes the last two video sets recorded from in class and combines them into a final frame_dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6be856d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from threading import Thread\n",
    "import sys\n",
    "\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c2abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GESTURE_NAMES = [\"CLOCKWISE\", \"COUNTERCLOCKWISE\", \"DOWN\", \"UP\", \"LEFT\", \"RIGHT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a80b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEOS_DIR = Path(\"D:/__School/__Masters/____2021fALL/5280_aiwearables/videos\")\n",
    "TARGET_DIR = Path(\"D:/__School/__Masters/____2021fALL/5280_aiwearables/3rd_iter_frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6b56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_names_all_videos(home_dir):\n",
    "    \"\"\"returns the names in a directories subfolders\"\"\"\n",
    "    video_fnames = []\n",
    "    for path, subdirs, files in os.walk(home_dir):\n",
    "        for name in files:\n",
    "            video_fnames.append(str(Path(os.path.join(path, name))))\n",
    "    return video_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8348c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir_names = get_dir_names_all_videos(VIDEOS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e59dfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_dir_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4626e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\__School\\\\__Masters\\\\____2021fALL\\\\5280_aiwearables\\\\videos\\\\Will_B\\\\CLOCKWISE\\\\WIN_20211027_17_25_02_Pro.mp4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_dir_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1fe3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_all_videos(video_dir_names):\n",
    "    fps_length_data = []\n",
    "    \n",
    "    for i, vid_dir in enumerate(video_dir_names):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"processing {i} of {len(video_dir_names)}...\")\n",
    "        split_dir = vid_dir.split(\"\\\\\")\n",
    "        fname = split_dir[-1]\n",
    "        gesture_name = split_dir[-2].replace(\" \", \"\").upper()\n",
    "        subject_initials = split_dir[-3]\n",
    "        \n",
    "        video = cv2.VideoCapture(str(vid_dir))\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration_seconds = frame_count / fps\n",
    "        \n",
    "        fps_length_data.append({\"file_name\": fname,\n",
    "                                \"subject_initials\": subject_initials,\n",
    "                                \"gesture_name\": gesture_name,\n",
    "                                \"frames_per_second\": fps,\n",
    "                                \"frame_count\": frame_count,\n",
    "                                \"duration_seconds\": duration_seconds,\n",
    "                                \"dir_name\": vid_dir})\n",
    "    df = pd.DataFrame(fps_length_data)\n",
    "    print(\"Done!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25312d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0 of 100...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df = get_metadata_all_videos(video_dir_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88cf7eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>subject_initials</th>\n",
       "      <th>gesture_name</th>\n",
       "      <th>frames_per_second</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>dir_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20211027_17_25_02_Pro.mp4</td>\n",
       "      <td>Will_B</td>\n",
       "      <td>CLOCKWISE</td>\n",
       "      <td>15.266469</td>\n",
       "      <td>33</td>\n",
       "      <td>2.1616</td>\n",
       "      <td>D:\\__School\\__Masters\\____2021fALL\\5280_aiwear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20211027_17_25_08_Pro.mp4</td>\n",
       "      <td>Will_B</td>\n",
       "      <td>CLOCKWISE</td>\n",
       "      <td>15.302687</td>\n",
       "      <td>25</td>\n",
       "      <td>1.6337</td>\n",
       "      <td>D:\\__School\\__Masters\\____2021fALL\\5280_aiwear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20211027_17_25_11_Pro.mp4</td>\n",
       "      <td>Will_B</td>\n",
       "      <td>CLOCKWISE</td>\n",
       "      <td>15.460546</td>\n",
       "      <td>26</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>D:\\__School\\__Masters\\____2021fALL\\5280_aiwear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_name subject_initials gesture_name  \\\n",
       "0  WIN_20211027_17_25_02_Pro.mp4           Will_B    CLOCKWISE   \n",
       "1  WIN_20211027_17_25_08_Pro.mp4           Will_B    CLOCKWISE   \n",
       "2  WIN_20211027_17_25_11_Pro.mp4           Will_B    CLOCKWISE   \n",
       "\n",
       "   frames_per_second  frame_count  duration_seconds  \\\n",
       "0          15.266469           33            2.1616   \n",
       "1          15.302687           25            1.6337   \n",
       "2          15.460546           26            1.6817   \n",
       "\n",
       "                                            dir_name  \n",
       "0  D:\\__School\\__Masters\\____2021fALL\\5280_aiwear...  \n",
       "1  D:\\__School\\__Masters\\____2021fALL\\5280_aiwear...  \n",
       "2  D:\\__School\\__Masters\\____2021fALL\\5280_aiwear...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21b44709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rounded_fps\"] = df.frames_per_second.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10ce891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0    50\n",
       "30.0    50\n",
       "Name: rounded_fps, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rounded_fps.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e4c83a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Will_B    50\n",
       "Yen_P     50\n",
       "Name: subject_initials, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subject_initials.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b0eb546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOWN                20\n",
       "LEFT                20\n",
       "RIGHT               20\n",
       "UP                  20\n",
       "CLOCKWISE           10\n",
       "COUNTERCLOCKWISE    10\n",
       "Name: gesture_name, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gesture_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c864d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    82\n",
       "1.0    13\n",
       "3.0     5\n",
       "Name: duration_seconds, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duration_seconds.round().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92cfc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_folder_names(df, gesture_names):\n",
    "    \"\"\"returns a dataframe with a new column formatted \n",
    "    <subject_initials>_<gesture_name>_<incremented_id>\n",
    "    based on gesture classes\"\"\"\n",
    "    df_list = []\n",
    "    \n",
    "    def for_each_row(row):\n",
    "        # build video filename\n",
    "        folder_name = f\"{row.subject_initials}_{row.gesture_name}_{row.increment_id:05d}\"\n",
    "        return folder_name\n",
    "    \n",
    "    for gesture_name in gesture_names:\n",
    "         # creates a new dataframe with increment values for each gesture\n",
    "        dff = df[df[\"gesture_name\"] == gesture_name].copy()\n",
    "        dff[\"increment_id\"] = np.arange(1, dff.shape[0]+1)\n",
    "        dff[\"gesture_video_foldername\"] = dff.apply(for_each_row, axis=1)\n",
    "        df_list.append(dff)\n",
    "    \n",
    "        \n",
    "    dff = pd.concat(df_list)\n",
    "    dff.reset_index(drop=True, inplace=True)\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "528cecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_video_folder_names(df, GESTURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d6b7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frames_directory(df, target_directory, gesture_names):\n",
    "    \"\"\"builds a directory for each class, and in each class a folder name\"\"\"\n",
    "    \n",
    "    def for_each_row(row):\n",
    "        # make internal video directories\n",
    "        gesture_dir = Path(target_directory).joinpath(row.gesture_name)\n",
    "        video_dir = gesture_dir.joinpath(row.gesture_video_foldername)\n",
    "        video_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    for gesture_name in gesture_names:\n",
    "        # make class directories\n",
    "        gesture_directory = Path(target_directory).joinpath(gesture_name)\n",
    "        gesture_directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df.apply(for_each_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c2850c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_frames_directory(df, TARGET_DIR, GESTURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5b0b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(input_dir, output_dir):\n",
    "    \"\"\"take in a video from input_dir and output the frames to the output_dir\"\"\"\n",
    "    video = cv2.VideoCapture(str(input_dir))\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for i in range(0, frame_count):\n",
    "        success, image = video.read()\n",
    "        if not success:\n",
    "            continue\n",
    "        cv2.imwrite( str(output_dir) + f\"\\\\img_{i+1:05d}.jpg\", image)     # save frame as JPEG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "befc5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will implement all the code necessary for the 50% faster image reading and saving\n",
    "\n",
    "class FileVideoStream:\n",
    "    def __init__(self, path, queueSize=160):\n",
    "        # initialize the file video stream along with the boolean\n",
    "        # used to indicate if the thread should be stopped or not\n",
    "        self.stream = cv2.VideoCapture(path)\n",
    "        self.stopped = False\n",
    "        # initialize the queue used to store frames read from\n",
    "        # the video file\n",
    "        self.Q = Queue(maxsize=queueSize)\n",
    "        \n",
    "    def start(self):\n",
    "        # start a thread to read frames from the file video stream\n",
    "        t = Thread(target=self.update, args=())\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "        return self\n",
    "    \n",
    "    def update(self):\n",
    "        # keep looping infinitely\n",
    "        while True:\n",
    "            # if the thread indicator variable is set, stop the\n",
    "            # thread\n",
    "            if self.stopped:\n",
    "                return\n",
    "            # otherwise, ensure the queue has room in it\n",
    "            if not self.Q.full():\n",
    "                # read the next frame from the file\n",
    "                (grabbed, frame) = self.stream.read()\n",
    "                # if the `grabbed` boolean is `False`, then we have\n",
    "                # reached the end of the video file\n",
    "                if not grabbed:\n",
    "                    self.stop()\n",
    "                    return\n",
    "                # add the frame to the queue\n",
    "                self.Q.put(frame)\n",
    "                \n",
    "    def read(self):\n",
    "        # return next frame in the queue\n",
    "        return self.Q.get()\n",
    "    \n",
    "    def more(self):\n",
    "        # return True if there are still frames in the queue\n",
    "        return self.Q.qsize() > 0\n",
    "    \n",
    "    def stop(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f9b255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_to_frames(input_file, output_dir, x, y):\n",
    "\n",
    "    fvs = FileVideoStream(input_file).start()\n",
    "    time.sleep(1.0)\n",
    "    \n",
    "    frame_count = 0\n",
    "    while fvs.more():\n",
    "        frame_count += 1\n",
    "        # grab the frame from the threaded video file stream, resize\n",
    "        # it, and convert it to grayscale (while still retaining 3\n",
    "        # channels)\n",
    "        frame = fvs.read()\n",
    "        frame = cv2.resize(frame, (x,y))\n",
    "        \n",
    "        # save frame to directory\n",
    "        cv2.imwrite( str(output_dir) + f\"\\\\img_{frame_count:05d}.jpg\", frame)\n",
    "        \n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    fvs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d205c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_frames(df, target_directory, gesture_names):\n",
    "    \"\"\"populate each of the video subfolders with individual frames from the videos\"\"\"\n",
    "    def per_row(row):\n",
    "        gesture_dir = Path(target_directory).joinpath(row.gesture_name)\n",
    "        output_video_dir = gesture_dir.joinpath(row.gesture_video_foldername)\n",
    "        input_video_dir = row.dir_name\n",
    "        print(f\"Processing {row.gesture_video_foldername}\")\n",
    "        process_video_to_frames(input_video_dir, output_video_dir, 320, 240)\n",
    "    df.apply(per_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f395abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Will_B_CLOCKWISE_00001\n",
      "Processing Will_B_CLOCKWISE_00002\n",
      "Processing Will_B_CLOCKWISE_00003\n",
      "Processing Will_B_CLOCKWISE_00004\n",
      "Processing Will_B_CLOCKWISE_00005\n",
      "Processing Yen_P_CLOCKWISE_00006\n",
      "Processing Yen_P_CLOCKWISE_00007\n",
      "Processing Yen_P_CLOCKWISE_00008\n",
      "Processing Yen_P_CLOCKWISE_00009\n",
      "Processing Yen_P_CLOCKWISE_00010\n",
      "Processing Will_B_COUNTERCLOCKWISE_00001\n",
      "Processing Will_B_COUNTERCLOCKWISE_00002\n",
      "Processing Will_B_COUNTERCLOCKWISE_00003\n",
      "Processing Will_B_COUNTERCLOCKWISE_00004\n",
      "Processing Will_B_COUNTERCLOCKWISE_00005\n",
      "Processing Yen_P_COUNTERCLOCKWISE_00006\n",
      "Processing Yen_P_COUNTERCLOCKWISE_00007\n",
      "Processing Yen_P_COUNTERCLOCKWISE_00008\n",
      "Processing Yen_P_COUNTERCLOCKWISE_00009\n",
      "Processing Yen_P_COUNTERCLOCKWISE_00010\n",
      "Processing Will_B_DOWN_00001\n",
      "Processing Will_B_DOWN_00002\n",
      "Processing Will_B_DOWN_00003\n",
      "Processing Will_B_DOWN_00004\n",
      "Processing Will_B_DOWN_00005\n",
      "Processing Will_B_DOWN_00006\n",
      "Processing Will_B_DOWN_00007\n",
      "Processing Will_B_DOWN_00008\n",
      "Processing Will_B_DOWN_00009\n",
      "Processing Will_B_DOWN_00010\n",
      "Processing Yen_P_DOWN_00011\n",
      "Processing Yen_P_DOWN_00012\n",
      "Processing Yen_P_DOWN_00013\n",
      "Processing Yen_P_DOWN_00014\n",
      "Processing Yen_P_DOWN_00015\n",
      "Processing Yen_P_DOWN_00016\n",
      "Processing Yen_P_DOWN_00017\n",
      "Processing Yen_P_DOWN_00018\n",
      "Processing Yen_P_DOWN_00019\n",
      "Processing Yen_P_DOWN_00020\n",
      "Processing Will_B_UP_00001\n",
      "Processing Will_B_UP_00002\n",
      "Processing Will_B_UP_00003\n",
      "Processing Will_B_UP_00004\n",
      "Processing Will_B_UP_00005\n",
      "Processing Will_B_UP_00006\n",
      "Processing Will_B_UP_00007\n",
      "Processing Will_B_UP_00008\n",
      "Processing Will_B_UP_00009\n",
      "Processing Will_B_UP_00010\n",
      "Processing Yen_P_UP_00011\n",
      "Processing Yen_P_UP_00012\n",
      "Processing Yen_P_UP_00013\n",
      "Processing Yen_P_UP_00014\n",
      "Processing Yen_P_UP_00015\n",
      "Processing Yen_P_UP_00016\n",
      "Processing Yen_P_UP_00017\n",
      "Processing Yen_P_UP_00018\n",
      "Processing Yen_P_UP_00019\n",
      "Processing Yen_P_UP_00020\n",
      "Processing Will_B_LEFT_00001\n",
      "Processing Will_B_LEFT_00002\n",
      "Processing Will_B_LEFT_00003\n",
      "Processing Will_B_LEFT_00004\n",
      "Processing Will_B_LEFT_00005\n",
      "Processing Will_B_LEFT_00006\n",
      "Processing Will_B_LEFT_00007\n",
      "Processing Will_B_LEFT_00008\n",
      "Processing Will_B_LEFT_00009\n",
      "Processing Will_B_LEFT_00010\n",
      "Processing Yen_P_LEFT_00011\n",
      "Processing Yen_P_LEFT_00012\n",
      "Processing Yen_P_LEFT_00013\n",
      "Processing Yen_P_LEFT_00014\n",
      "Processing Yen_P_LEFT_00015\n",
      "Processing Yen_P_LEFT_00016\n",
      "Processing Yen_P_LEFT_00017\n",
      "Processing Yen_P_LEFT_00018\n",
      "Processing Yen_P_LEFT_00019\n",
      "Processing Yen_P_LEFT_00020\n",
      "Processing Will_B_RIGHT_00001\n",
      "Processing Will_B_RIGHT_00002\n",
      "Processing Will_B_RIGHT_00003\n",
      "Processing Will_B_RIGHT_00004\n",
      "Processing Will_B_RIGHT_00005\n",
      "Processing Will_B_RIGHT_00006\n",
      "Processing Will_B_RIGHT_00007\n",
      "Processing Will_B_RIGHT_00008\n",
      "Processing Will_B_RIGHT_00009\n",
      "Processing Will_B_RIGHT_00010\n",
      "Processing Yen_P_RIGHT_00011\n",
      "Processing Yen_P_RIGHT_00012\n",
      "Processing Yen_P_RIGHT_00013\n",
      "Processing Yen_P_RIGHT_00014\n",
      "Processing Yen_P_RIGHT_00015\n",
      "Processing Yen_P_RIGHT_00016\n",
      "Processing Yen_P_RIGHT_00017\n",
      "Processing Yen_P_RIGHT_00018\n",
      "Processing Yen_P_RIGHT_00019\n",
      "Processing Yen_P_RIGHT_00020\n"
     ]
    }
   ],
   "source": [
    "populate_frames(df, TARGET_DIR, GESTURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05685b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
